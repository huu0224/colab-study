# -*- coding: utf-8 -*-
"""데이터로드/탐색/전처리.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MscdoFA7kMe4YCmdWPTWO2HPetWad6Ls
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""**[A]데이터로드/탐색/전처리**

1) 데이터 로드 및 출력
"""

# bash 명령어를 사용하여 파일을 처음 5줄 출력(header 여부를 판단하기 위함)
# 큰 용량의 파일의 경우, 파일 전체를 열어서 보지 않도록 주의!!!
# 주의사항 : Colab Notebookds에 있는 빈칸은 제어문자로 처리해야 함
!head -n 5 /content/drive/MyDrive/Colab\ Notebooks/ML2024/ThoracicSurgery.csv

thoracic = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML2024_A/ThoracicSurgery.csv', index_col='id')

thoracic = thoracic.drop('DGN', axis=1)

thoracic.head()

thoracic.shape

"""2) 결측치 파악

결측치는 dataframe.isnull().sum()을 사용하거나 dataframe.inf0()를 사용하면 알 수 있다.
"""

thoracic.isnull().sum()

thoracic.info()

"""결측치는 없음

3) 특성행렬과 타겟 벡터 만들기
"""

y = thoracic['Risk1Yr']  #타겟 벡터

X = thoracic.drop('Risk1Yr', axis=1)  #특성 행렬

"""4) 데이터 분할"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1, stratify=y)

y_train.value_counts() / y_train.shape[0]  #혹은 y_train.value_counts(normalize=True)

y_test.value_counts() / y_test.shape[0]  #혹은 y_test.value_counts(normalize=True)

"""훈련셋과 테스트셋의 F vs T의 비율이 유사함

5) 레이블 인코딩
"""

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
label_encoder.fit(y_train)
label_encoder.classes_

y_train = label_encoder.transform(y_train)  # F는 0으로, T는 1로 인코딩

y_train

"""6) 특성의 데이터 타입 파악"""

X_train.info()

"""문자열은 object, 정수형은 int64, 부동소수점형은 float64"""

num = ['PRE4', 'PRE5', 'AGE']   # 수치형 특성

cat = list(set(X_train.columns) - set(num))   # 범주형 특성

cat

"""7) 연속성 특성 분석

전처리를 위하여 연속형 특성 행렬(X_train_num)과 범주형 특성 행렬(X_train_cat)로 분리한 후, 처리 후 합친다.
"""

#연속형 특성 분리
X_train_num = X_train[num]
X_train_num.describe()

"""8) 범주형 특성 분석"""

cat

# 방법1 : 판다스 unique 메서드 활용
for col in cat:
  print(col, ':', X_train[col].unique())

# 방법2 : 판다스 value_counts 메서드 활용
for col in cat:
  print(X_train[col].value_counts())

"""범주형 특성 중 PRE6는 3개의 범주, PRE14는 4개의 범주를 갖고, 나머지 10개 특성은 모두 2개의 범주를 갖는다.

9) 범주형 특성 인코딩
"""

# 범주형 특성 분리하기
X_train_cat = X_train[cat]

X_train_cat.head()

from sklearn.preprocessing import OneHotEncoder
one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first', feature_name_combiner='concat')

one_hot_encoder.fit(X_train_cat)

# 생성된 가변수의 이름(의미)
one_hot_encoder.get_feature_names_out()

"""총 15개의 가변수를 생성한다. (15 = 3 + 2 + 10 * 1)"""

X_train_cat_encoded = pd.DataFrame(one_hot_encoder.transform(X_train_cat),
                                   columns = one_hot_encoder.get_feature_names_out(),
                                   index=X_train_cat.index)

X_train_cat_encoded.head()

X_train_num

X_train_encoded = pd.concat([X_train_num, X_train_cat_encoded], axis=1)

X_train_encoded

"""10) 훈련 데이터 표준화"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X_train_std = scaler.fit_transform(X_train_encoded)

X_train_std

"""11) 테스트 데이터 전처리"""

# 레이블 인코딩
y_test = label_encoder.transform(y_test)
# 연속형 특성 분리하기
X_test_num = X_test[num]
 # 범주형 특성 분리하기
X_test_cat = X_test[cat]
# 범주형 특성 인코딩
X_test_cat_encoded = pd.DataFrame(one_hot_encoder.transform(X_test_cat),
                                   columns = one_hot_encoder.get_feature_names_out(),
                                   index=X_test_cat.index)
# 특성 행렬 결합
X_test_encoded = pd.concat([X_test_num, X_test_cat_encoded], axis=1)
# 특성 행렬 표준화
X_test_std = scaler.transform(X_test_encoded)

X_test_encoded

X_test_std